{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "# External\n",
    "import BatchMaker\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Built-Ins\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "# Version control\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the Data\n",
    "fig = plt.figure(figsize = (30,30))\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax1.set_title('Input frame (aps)')\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.set_title('According Label')\n",
    "\n",
    "x = Image.open('Data/frames/frame-0253.png').getchannel(0)\n",
    "y = Image.open('Data/labels/label-0253.png')\n",
    "\n",
    "x = TF.to_tensor(x)\n",
    "y = TF.to_tensor(y)\n",
    "\n",
    "sns.heatmap(x[0], cmap='gray', vmin=0, vmax=1, ax=ax1, square=True, cbar_kws={'shrink': .6})\n",
    "sns.heatmap(y[0], ax=ax2, square=True, cbar_kws={'shrink': .6})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "path_file = \"data.csv\"\n",
    "\n",
    "train_inputs, train_labels, val_inputs, val_labels = BatchMaker.BatchMaker(path_file)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "#     transforms.Resize((165, 220)),\n",
    "    transforms.RandomRotation(degrees=random.randint(0,360)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "\n",
    "])\n",
    "\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, inputs, labels, transform=transform):\n",
    "        self.inputs = torch.FloatTensor(inputs)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.inputs[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            seed = np.random.randint(2147483647) \n",
    "            random.seed(seed)\n",
    "\n",
    "            x = self.transform(x)\n",
    "            if random.random() > 0.5:\n",
    "                x = TF.adjust_brightness(x, random.uniform(0.4,0.6))\n",
    "\n",
    "            if random.random() > 0.5:\n",
    "                x = TF.adjust_contrast(x, random.uniform(0.4,0.6))\n",
    "            x = TF.to_tensor(x)\n",
    "\n",
    "            random.seed(seed)\n",
    "            y = self.transform(y)\n",
    "            y = TF.to_tensor(y)\n",
    "            \n",
    "        y = y/np.sum(np.array(y))\n",
    "        \n",
    "        return x.view(1,180,240), y.view(1,180,240)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    \n",
    "# Get the data, transform it\n",
    "data = {\n",
    "   'train':\n",
    "   CreateDataset(train_inputs, train_labels),\n",
    "   'val':\n",
    "   CreateDataset(val_inputs, val_labels, transform=None),\n",
    "#     'test':\n",
    "#    CreateDataset(test_inputs, test_labels, transform=None)\n",
    "}\n",
    "\n",
    "# Load Data in batches, shuffled\n",
    "dataloaders = {\n",
    "   'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True, drop_last=True),\n",
    "   'val': DataLoader(data['val'], batch_size=batch_size, shuffle=False, drop_last=True),\n",
    "#     'test': DataLoader(data['test'], batch_size=batch_size, shuffle=False, drop_last=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "    \n",
    "        self.layer2 = nn.Sequential( \n",
    "            nn.Conv2d(64, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, padding=0))\n",
    "            \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, padding=0))\n",
    "            \n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer10 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "            \n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer14 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "            \n",
    "        self.layer15 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "            \n",
    "        self.layer16 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "            \n",
    "        self.layer17 = nn.Sequential(\n",
    "            nn.Conv2d(64, 1,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1))\n",
    "        \n",
    "        self.layer18 = nn.Softmax(dim=1)\n",
    "            \n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)  \n",
    "        x = self.layer2(x)  \n",
    "        x = self.layer3(x)  \n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)  \n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer9(x)  \n",
    "        x = self.layer10(x)  \n",
    "        x = self.layer11(x)  \n",
    "        x = self.layer12(x)  \n",
    "        x = self.layer13(x)  \n",
    "        x = self.layer14(x)  \n",
    "        x = self.layer15(x)  \n",
    "        x = self.layer16(x)\n",
    "        x = self.layer17(x) \n",
    "        x = x.view(1, -1)\n",
    "        x = self.layer18(x)\n",
    "        x = x.reshape(1, 180, 240)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and move the model over to GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda: 0\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    print(f\"Running on your {gpu_name} (GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on your CPU\")\n",
    "\n",
    "net = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss function: LAD-Loss + distance factor\n",
    "def distance(output, target):\n",
    "    center_output = np.where(output==np.amax(output))\n",
    "    center_target = np.where(target==np.amax(target))\n",
    "    \n",
    "    if center_target[0].size == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            x1 = center_output[1][0]\n",
    "            y1 = center_output[0][0]\n",
    "            x2 = center_target[1][0]\n",
    "            y2 = center_target[0][0]\n",
    "\n",
    "            distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            return distance\n",
    "        except:\n",
    "            print(center_target[0])\n",
    "\n",
    "loss_fn = nn.L1Loss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1\n",
    "epochs_no_improve_limit = 7\n",
    "plot_heatmaps = False\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "def train():\n",
    "    epochs_no_improve = 0\n",
    "    min_val_loss = np.Inf\n",
    "    since = time.time()\n",
    "    iteration = 0\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "        print('-' * 10)\n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        num = 10\n",
    "        \n",
    "        for train_inputs, train_labels in dataloaders['train']:            \n",
    "                optimizer.zero_grad()\n",
    "                output = net(torch.from_numpy(np.array(train_inputs)).to(device))\n",
    "                loss = loss_fn(output[0].cpu(), torch.from_numpy(np.array(train_labels)[0][0]).cpu())*4*(distance(output[0].cpu().detach().numpy(), np.array(train_labels)[0][0])/8)\n",
    "                train_loss += loss\n",
    "\n",
    "                if plot_heatmaps:\n",
    "                    fig = plt.figure(figsize = (32,24))\n",
    "                    ax1 = fig.add_subplot(3, 3, 1)\n",
    "                    ax1.set_title('Input frame (aps)')\n",
    "                    ax2 = fig.add_subplot(3, 3, 2)\n",
    "                    ax2.set_title('Label')\n",
    "                    ax3 = fig.add_subplot(3, 3, 3)\n",
    "                    ax3.set_title('Output of the FCN')\n",
    "                    sns.heatmap(train_inputs[0][0], vmin=0, vmax=1, cmap='gray', ax=ax1, cbar_kws={'shrink': .9})\n",
    "                    try:\n",
    "                        sns.heatmap(train_labels[0][0], ax=ax2, cbar_kws={'shrink': .9})\n",
    "                    except ValueError:  #raised if `train_labels` is empty.\n",
    "                        pass\n",
    "                    \n",
    "                    sns.heatmap(output[0].cpu().detach().numpy(), ax=ax3, cbar_kws={'shrink': .9})\n",
    "                    plt.show()\n",
    "\n",
    "                print('Training Loss: {:.4f}'.format(loss.item()))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(float(loss))\n",
    "                iteration += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in dataloaders['val']:\n",
    "                \n",
    "                output = net(torch.from_numpy(np.array(val_inputs)).to(device))\n",
    "                loss = loss_fn(output[0].cpu(), torch.from_numpy(np.array(val_labels)[0][0]).cpu())*(distance(output[0].cpu().detach().numpy(), np.array(val_labels)[0][0])/4)\n",
    "                val_loss += loss\n",
    "\n",
    "            val_loss = val_loss / len(dataloaders['val'])\n",
    "            val_losses.append(float(val_loss))\n",
    "            print('-' * 10)\n",
    "            print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "\n",
    "            if val_loss < min_val_loss:\n",
    "                torch.save({'state_dict': net.state_dict()}, 'Nets/pt-labi_CNN.pt')\n",
    "                epochs_no_improve = 0\n",
    "                min_val_loss = val_loss\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve == epochs_no_improve_limit:\n",
    "                    print('Early stopping initiated')\n",
    "                    model = torch.load('Nets/pt-labi_CNN.pt')\n",
    "                    print('Best model so far has been loaded')\n",
    "\n",
    "    print('Least validation Loss: {:4f}'.format(min_val_loss))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Finished training')\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_losses)\n",
    "print(val_losses)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training- vs. Validation-Loss')\n",
    "plt.ylabel('Modified LAD-Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(256, 6))\n",
    "line_weight = 3\n",
    "alpha = .8\n",
    "ax1 = fig.add_axes([0, 0, 1, 1])\n",
    "ax2 = fig.add_axes()\n",
    "ax2 = ax1.twiny()\n",
    "lns1 = ax1.plot(train_losses, color='blue', lw=line_weight, alpha=alpha, label='Training Losses')\n",
    "lns2 = ax2.plot(val_losses, color='orange', lw=line_weight, alpha=alpha, label='Validation Losses')\n",
    "leg = lns1 + lns2\n",
    "labs = [l.get_label() for l in leg]\n",
    "ax1.legend(leg, labs, loc='upper right')\n",
    "plt.title('Training- vs. Validation-Loss', fontsize=15)\n",
    "plt.ylabel('Modified LAD-Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_heatmaps = False\n",
    "write_output = False\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    iteration = 0\n",
    "    num_test_samples = 100\n",
    "    with torch.no_grad():\n",
    "        for idx, (test_inputs, test_labels) in enumerate(dataloaders['val']):\n",
    "            if idx >= num_test_samples:\n",
    "                break\n",
    "            else:\n",
    "                output = net(torch.from_numpy(np.array(test_inputs)).to(device))\n",
    "                test_labels = np.divide(test_labels, np.sum(np.array(test_labels)))\n",
    "                loss = loss_fn(output[0].cpu(), torch.from_numpy(np.array(test_labels)[0][0]).cpu())*(distance(output[0].cpu().detach().numpy(), np.array(test_labels)[0][0])/4)\n",
    "                test_loss += loss\n",
    "                if write_output:\n",
    "                    FileName = f'Data/OutputMovie/output-%04d.png' % iteration\n",
    "                    cv2.imwrite(FileName, np.float32(output.cpu()[0]) * 20000)\n",
    "                if plot_heatmaps:\n",
    "                    fig = plt.figure(figsize = (32,24))\n",
    "                    ax1 = fig.add_subplot(2, 2, 1)\n",
    "                    ax1.set_title('Output')\n",
    "                    ax2 = fig.add_subplot(2, 2, 2)\n",
    "                    ax2.set_title('Label')\n",
    "                    sns.heatmap(output[0].cpu().detach().numpy(),ax=ax1, square=True, cbar_kws={'shrink': .8})\n",
    "                    sns.heatmap(test_labels[0][0], ax=ax2, square=True, cbar_kws={'shrink': .8})\n",
    "                    plt.show()\n",
    "                iteration += 1\n",
    "        \n",
    "        test_loss = test_loss/num_test_samples\n",
    "        print('Average test loss: ' ,test_loss.numpy())\n",
    "        print('Testing completed')\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
