{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0\n",
      "Torchvision Version:  0.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import BatchMaker\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(9, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "    \n",
    "        self.layer2 = nn.Sequential( \n",
    "            nn.Conv2d(64, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, padding=0))\n",
    "            \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, padding=0))\n",
    "            \n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer10 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "            \n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer14 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "            \n",
    "        self.layer15 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "            \n",
    "        self.layer16 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "            \n",
    "        self.layer17 = nn.Sequential(\n",
    "            nn.Conv2d(64, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer18 = nn.Softmax(dim=2)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)  \n",
    "        x = self.layer2(x)  \n",
    "        x = self.layer3(x)  \n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)  \n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer9(x)  \n",
    "        x = self.layer10(x)  \n",
    "        x = self.layer11(x)  \n",
    "        x = self.layer12(x)  \n",
    "        x = self.layer13(x)  \n",
    "        x = self.layer14(x)  \n",
    "        x = self.layer15(x)  \n",
    "        x = self.layer16(x)\n",
    "        x = self.layer17(x) \n",
    "        print(x.shape())\n",
    "        x = self.layer18(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on your GeForce GTX 1080 (GPU)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and move the model over to GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda: 0\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    print(f\"Running on your {gpu_name} (GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on your CPU\")\n",
    "\n",
    "net = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator = BatchMaker.BatchMaker\n",
    "\n",
    "batch_size = 1\n",
    "training_file = \"training_model.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (int, int, int, int), but expected one of:\n * (name dim0, name dim1)\n * (int dim0, int dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4a7ceaa18703>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training complete in {:.0f}m {:.0f}s'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_elapsed\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-4a7ceaa18703>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (int, int, int, int), but expected one of:\n * (name dim0, name dim1)\n * (int dim0, int dim1)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.L1Loss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1\n",
    "epochs_no_improve_limit = 7\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "def train():\n",
    "    epochs_no_improve = 0\n",
    "    min_val_loss = np.Inf\n",
    "    since = time.time()\n",
    "    iteration = 0\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "        print('-' * 10)\n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        for train_inputs, train_labels in Generator(training_file, batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            output = net(torch.from_numpy(train_inputs).transpose(0,3,1,2).to(device))\n",
    "            loss = loss_fn(output.cpu(), torch.from_numpy(train_labels).cpu())\n",
    "            train_loss += loss\n",
    "            \n",
    "#             fig = plt.figure(figsize = (32,24))\n",
    "#             ax1 = fig.add_subplot(2, 2, 1)\n",
    "#             ax1.set_title('Input red')\n",
    "#             ax2 = fig.add_subplot(2, 2, 2)\n",
    "#             ax2.set_title('Input green')\n",
    "#             ax3 = fig.add_subplot(2, 2, 3)\n",
    "#             ax3.set_title('Label')\n",
    "#             ax4 = fig.add_subplot(2, 2, 4)\n",
    "#             ax4.set_title('Output of the CNN')\n",
    "\n",
    "#             sns.heatmap(train_inputs[0][0], vmin=0, vmax=1, cmap='gray', ax=ax1, cbar_kws={'shrink': .9})\n",
    "#             sns.heatmap(train_inputs[0][1], vmin=0, vmax=1, ax=ax2, cbar_kws={'shrink': .9})\n",
    "#             sns.heatmap(train_labels[0][0], vmin=0, vmax=1, ax=ax3, cbar_kws={'shrink': .9})\n",
    "#             sns.heatmap(output.cpu().detach().numpy()[0], vmin=0, vmax=1, ax=ax4, cbar_kws={'shrink': .9})\n",
    "#             plt.show()\n",
    "\n",
    "\n",
    "#             writer.add_scalar('Loss/train', loss, iteration)\n",
    "\n",
    "            print('Training Loss: {:.4f}'.format(loss.item()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iteration += 1\n",
    "        \n",
    "        train_loss = train_loss / len(dataloaders['train'])\n",
    "        train_losses.append(float(train_loss))\n",
    "        \n",
    "        del train_inputs\n",
    "        del train_labels\n",
    "        del output\n",
    "        del loss\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for val_inputs, val_labels in dataloaders['val']:\n",
    "#                 torch.cuda.empty_cache()\n",
    "#                 output = net(val_inputs.to(device)).reshape(batch_size, output_height, output_width)\n",
    "#                 loss = loss_fn(output.cpu(), val_labels.cpu().reshape(batch_size, output_height, output_width))\n",
    "#                 val_loss += loss\n",
    "\n",
    "#             val_loss = val_loss / len(dataloaders['val'])\n",
    "#             val_losses.append(float(val_loss))\n",
    "#             print('-' * 10)\n",
    "#             print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "\n",
    "#             if val_loss < min_val_loss:\n",
    "#                 torch.save({'state_dict': net.state_dict()}, 'Nets/pt-labi_CNN.pt')\n",
    "#                 epochs_no_improve = 0\n",
    "#                 min_val_loss = val_loss\n",
    "#             else:\n",
    "#                 epochs_no_improve += 1\n",
    "#                 if epochs_no_improve == epochs_no_improve_limit:\n",
    "#                     print('Early stopping initiated')\n",
    "#                     model = torch.load('Nets/pt-labi_CNN.pt')\n",
    "#                     print('Best model so far has been loaded')\n",
    "    print('Least validation Loss: {:4f}'.format(min_val_loss))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Finished training')\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 180, 240, 9])\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "for train_inputs, train_labels in Generator(training_file, batch_size):\n",
    "    lol = torch.from_numpy(train_inputs)\n",
    "    print(lol.size())\n",
    "    print(train_labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
