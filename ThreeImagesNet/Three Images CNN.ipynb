{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0\n",
      "Torchvision Version:  0.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import BatchMaker\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "    \n",
    "        self.layer2 = nn.Sequential( \n",
    "            nn.Conv2d(64, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, padding=0))\n",
    "            \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, padding=0))\n",
    "            \n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256))\n",
    "            \n",
    "        self.layer10 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "            \n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128))\n",
    "            \n",
    "        self.layer14 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "            \n",
    "        self.layer15 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "            \n",
    "        self.layer16 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64))\n",
    "            \n",
    "        self.layer17 = nn.Sequential(\n",
    "            nn.Conv2d(64, 1,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1))\n",
    "            \n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)  \n",
    "        x = self.layer2(x)  \n",
    "        x = self.layer3(x)  \n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)  \n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer9(x)  \n",
    "        x = self.layer10(x)  \n",
    "        x = self.layer11(x)  \n",
    "        x = self.layer12(x)  \n",
    "        x = self.layer13(x)  \n",
    "        x = self.layer14(x)  \n",
    "        x = self.layer15(x)  \n",
    "        x = self.layer16(x)\n",
    "        x = self.layer17(x) \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on your GeForce GTX 1080 (GPU)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and move the model over to GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda: 0\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    print(f\"Running on your {gpu_name} (GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on your CPU\")\n",
    "\n",
    "net = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator = BatchMaker.BatchMaker\n",
    "\n",
    "batch_size = 1\n",
    "training_file = \"training.csv\"\n",
    "testing_file = \"testing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "(180, 240)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a0775e4b0e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training complete in {:.0f}m {:.0f}s'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_elapsed\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-a0775e4b0e33>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mtrain_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\elias\\Documents\\School\\Maturaarbeit\\CNN_ER_FA\\ThreeImagesNet\\BatchMaker.py\u001b[0m in \u001b[0;36mBatchMaker\u001b[1;34m(images_path, batch_size)\u001b[0m\n\u001b[0;32m     54\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m          \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m          \u001b[0mInput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mThreeImagesInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m          \u001b[0mOutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\elias\\Documents\\School\\Maturaarbeit\\CNN_ER_FA\\ThreeImagesNet\\BatchMaker.py\u001b[0m in \u001b[0;36mThreeImagesInput\u001b[1;34m(path, path1, path2)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m    \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m    \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m    \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m    \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.L1Loss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1\n",
    "epochs_no_improve_limit = 7\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "def train():\n",
    "    epochs_no_improve = 0\n",
    "    min_val_loss = np.Inf\n",
    "    since = time.time()\n",
    "    iteration = 0\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "        print('-' * 10)\n",
    "        val_loss = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        for train_inputs, train_labels in Generator(training_file, batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            train_inputs = train_inputs.transpose(0,3,1,2)\n",
    "            output = net(torch.from_numpy(train_inputs).to(device))\n",
    "            loss = loss_fn(output[0].cpu(), torch.from_numpy(train_labels).cpu())\n",
    "            train_loss += loss\n",
    "            \n",
    "            FileName = f'Data/Output/output-%04d.png' % iteration\n",
    "            \n",
    "            cv2.imwrite(FileName, np.float32(output[0][0].cpu().detach().numpy()) * 255)\n",
    "            \n",
    "            fig = plt.figure(figsize = (32,24))\n",
    "            ax1 = fig.add_subplot(2, 2, 1)\n",
    "            ax1.set_title('Input red')\n",
    "            ax2 = fig.add_subplot(2, 2, 2)\n",
    "            ax2.set_title('Input green')\n",
    "            ax3 = fig.add_subplot(2, 2, 3)\n",
    "            ax3.set_title('Label')\n",
    "            ax4 = fig.add_subplot(2, 2, 4)\n",
    "            ax4.set_title('Output of the CNN')\n",
    "            \n",
    "            sns.heatmap(train_inputs[0][2], vmin=0, vmax=1, cmap='gray', ax=ax1, cbar_kws={'shrink': .9})\n",
    "            sns.heatmap(train_inputs[0][1], vmin=0, vmax=1, ax=ax2, cbar_kws={'shrink': .9})\n",
    "            sns.heatmap(train_labels[0], vmin=0, vmax=1, ax=ax3, cbar_kws={'shrink': .9})\n",
    "            sns.heatmap(output[0].cpu().detach().numpy()[0], vmin=0, vmax=1, ax=ax4, cbar_kws={'shrink': .9})\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "#             writer.add_scalar('Loss/train', loss, iteration)\n",
    "\n",
    "            print('Training Loss: {:.4f}'.format(loss.item()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iteration += 1\n",
    "        \n",
    "        train_loss = train_loss / len(dataloaders['train'])\n",
    "        train_losses.append(float(train_loss))\n",
    "        \n",
    "        del train_inputs\n",
    "        del train_labels\n",
    "        del output\n",
    "        del loss\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for val_inputs, val_labels in dataloaders['val']:\n",
    "#                 torch.cuda.empty_cache()\n",
    "#                 output = net(val_inputs.to(device)).reshape(batch_size, output_height, output_width)\n",
    "#                 loss = loss_fn(output.cpu(), val_labels.cpu().reshape(batch_size, output_height, output_width))\n",
    "#                 val_loss += loss\n",
    "\n",
    "#             val_loss = val_loss / len(dataloaders['val'])\n",
    "#             val_losses.append(float(val_loss))\n",
    "#             print('-' * 10)\n",
    "#             print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "\n",
    "#             if val_loss < min_val_loss:\n",
    "#                 torch.save({'state_dict': net.state_dict()}, 'Nets/pt-labi_CNN.pt')\n",
    "#                 epochs_no_improve = 0\n",
    "#                 min_val_loss = val_loss\n",
    "#             else:\n",
    "#                 epochs_no_improve += 1\n",
    "#                 if epochs_no_improve == epochs_no_improve_limit:\n",
    "#                     print('Early stopping initiated')\n",
    "#                     model = torch.load('Nets/pt-labi_CNN.pt')\n",
    "#                     print('Best model so far has been loaded')\n",
    "    print('Least validation Loss: {:4f}'.format(min_val_loss))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Finished training')\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_width = 240\n",
    "output_height = 180\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    num_test_samples = 10\n",
    "    with torch.no_grad():\n",
    "        for idx, (test_inputs, test_labels) in enumerate(Generator(testing_file, 1)):\n",
    "            if idx >= num_test_samples:\n",
    "                break\n",
    "            else:\n",
    "                output = net(torch.from_numpy(test_inputs.transpose(0,3,1,2)).to(device))\n",
    "                loss = loss_fn(output[0].cpu(), torch.from_numpy(test_labels).cpu())\n",
    "                output = output[0].reshape(output_height, output_width).cpu().detach().numpy()\n",
    "                test_labels = test_labels[0].reshape(output_height, output_width)\n",
    "                test_loss += loss\n",
    "\n",
    "                fig = plt.figure(figsize = (32,24))\n",
    "                ax1 = fig.add_subplot(2, 2, 1)\n",
    "                ax1.set_title('Output')\n",
    "                ax2 = fig.add_subplot(2, 2, 2)\n",
    "                ax2.set_title('Label')\n",
    "\n",
    "                sns.heatmap(output, vmin=0, vmax=1, ax=ax1, square=True, cbar_kws={'shrink': .8})\n",
    "                sns.heatmap(test_labels, vmin=0, vmax=1, ax=ax2, square=True, cbar_kws={'shrink': .8})\n",
    "                plt.show()\n",
    "        \n",
    "        test_loss = test_loss/num_test_samples\n",
    "        print('Average test loss: ' ,test_loss.numpy())\n",
    "        print('Testing completed')\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
