{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.1.0\n",
      "Torchvision Version:  0.3.0\n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries needed\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2170, 2, 100, 100)\n",
      "(1, 2, 100, 100)\n",
      "(1, 2, 100, 100)\n",
      "(2170, 100, 100)\n",
      "(1, 100, 100)\n",
      "(1, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# Define the transformations/augmentations for the data\n",
    "array_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "# Tell the dataloader where to search\n",
    "traindir = 'Data/traindir'\n",
    "train_channels = [f'{traindir}/r_data', f'{traindir}/g_data']\n",
    "\n",
    "valdir = 'Data/valdir'\n",
    "val_channels = [f'{valdir}/r_data', f'{valdir}/g_data']\n",
    "\n",
    "testdir = 'Data/testdir'\n",
    "test_channels = [f'{testdir}/r_data', f'{testdir}/g_data']\n",
    "\n",
    "train_inputs = []\n",
    "train_labels = []\n",
    "\n",
    "val_inputs = []\n",
    "val_labels = []\n",
    "\n",
    "test_inputs = []\n",
    "test_labels = []\n",
    "\n",
    "def load_npy_arrays(phase):\n",
    "    \n",
    "    if phase == \"train\":\n",
    "        phase_channels = train_channels\n",
    "        phase_inputs = train_inputs\n",
    "        phasedir = traindir\n",
    "        phase_labels = train_labels\n",
    "    \n",
    "    elif phase == \"val\":\n",
    "        phase_channels = val_channels\n",
    "        phase_inputs = val_inputs\n",
    "        phasedir = valdir\n",
    "        phase_labels = val_labels\n",
    "    \n",
    "    elif phase == \"test\":\n",
    "        phase_channels = test_channels\n",
    "        phase_inputs = test_inputs\n",
    "        phasedir = testdir\n",
    "        phase_labels = test_labels\n",
    "    \n",
    "    else:\n",
    "        print('Valueerror: please pass one of the three accepted values(train, val, test)')\n",
    "\n",
    "    for channel in phase_channels:\n",
    "        path_to_channel = os.fsdecode(channel)\n",
    "        for file in os.listdir(channel):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith('.npy'):\n",
    "                loaded_array = np.load(f'{path_to_channel}/{filename}')\n",
    "                phase_inputs.append(loaded_array)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    labelfolder = f'{phasedir}/labels'\n",
    "    for file in os.listdir(labelfolder):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith('.npy'):\n",
    "            loaded_array = np.load(f'{labelfolder}/{filename}')\n",
    "            phase_labels.append(loaded_array)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "load_npy_arrays(\"train\")\n",
    "load_npy_arrays(\"val\")\n",
    "load_npy_arrays(\"test\")\n",
    "\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, inputs, labels, transform=None):\n",
    "        self.inputs = inputs\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.inputs[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(self.inputs[index].astype(np.uint8).transpose(1,2,0))\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "# Split up the red and green channel again so that the axes match in size\n",
    "train_inputs = np.asarray(train_inputs)\n",
    "train_inputs = np.split(train_inputs, 2, axis=0)\n",
    "train_inputs = np.asarray(train_inputs).transpose(1,0,2,3)\n",
    "print(np.shape(train_inputs))\n",
    "\n",
    "val_inputs = np.asarray(val_inputs)\n",
    "val_inputs = np.split(val_inputs, 2, axis=0)\n",
    "val_inputs = np.asarray(val_inputs).transpose(1,0,2,3)\n",
    "print(np.shape(val_inputs))\n",
    "\n",
    "test_inputs = np.asarray(test_inputs)\n",
    "test_inputs = np.split(test_inputs, 2, axis=0)\n",
    "test_inputs = np.asarray(test_inputs).transpose(1,0,2,3)\n",
    "print(np.shape(test_inputs))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(val_labels))\n",
    "print(np.shape(test_labels))\n",
    "\n",
    "# Get the data, transform it\n",
    "data = {\n",
    "   'train':\n",
    "   CreateDataset(torch.FloatTensor(train_inputs), train_labels, transform = None),\n",
    "   'val':\n",
    "   CreateDataset(torch.FloatTensor(val_inputs), val_labels, transform = None),\n",
    "    'test':\n",
    "   CreateDataset(torch.FloatTensor(test_inputs), test_labels, transform = array_transforms['test']),\n",
    "}\n",
    "\n",
    "# Load Data in batches, shuffled\n",
    "dataloaders = {\n",
    "   'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "   'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): Identity()\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): Identity()\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): Identity()\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): Identity()\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load in pretrained VGG16 net, extract the FCN part, delete pooling layers,\n",
    "# and modify first layer to recieve 2 channels\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16_mod = vgg16.features\n",
    "vgg16_mod[0] = nn.Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "vgg16_mod[4] = nn.Identity()\n",
    "vgg16_mod[9] = nn.Identity()\n",
    "vgg16_mod[16] = nn.Identity()\n",
    "vgg16_mod[23] = nn.Identity()\n",
    "vgg16_mod[30] = nn.Identity()\n",
    "print(vgg16_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on your GeForce 920M (GPU)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and move the model over to GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda: 0\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    print(f\"Running on your {gpu_name} (GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on your CPU\")\n",
    "\n",
    "net = vgg16_mod.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and the optimizer\n",
    "\n",
    "def LAD_loss(output, target):\n",
    "    print(output.size())\n",
    "    print(target.size())\n",
    "    ladloss = np.sum(np.abs(target-output))\n",
    "    return ladloss\n",
    "\n",
    "def pytagorean_loss(output, target):\n",
    "    \n",
    "    def distance(x1,y1,x2,y2):\n",
    "        return ((x2-x1)**2 + (y2-y1)**2)**0.5\n",
    "    \n",
    "    out_max = torch.max(output)\n",
    "    target_max = torch.max(target)\n",
    "    \n",
    "    x1 = list(list(zip(*np.where(output==out_max)))[0])[0]\n",
    "    y1 = list(list(zip(*np.where(output==out_max)))[0])[1]\n",
    "    x2 = list(list(zip(*np.where(target==target_max)))[0])[1]\n",
    "    y2 = list(list(zip(*np.where(target==target_max)))[0])[2]\n",
    "    return distance(x1,y1,x2,y2)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 100, 100])\n",
      "torch.Size([1, 512, 100, 100])\n",
      "torch.Size([1, 100, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-380fb4f12642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best model so far has been loaded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-148-380fb4f12642>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLAD_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-147-faffc66ee621>\u001b[0m in \u001b[0;36mLAD_loss\u001b[1;34m(output, target)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mladloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mladloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt-labi\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Define the training loop\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "epochs_no_improve = 0\n",
    "epochs_no_improve_limit = 7\n",
    "\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "\n",
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        val_loss = 0\n",
    "        \n",
    "        for train_inputs, train_labels in dataloaders['train']:\n",
    "            optimizer.zero_grad()\n",
    "            print(train_inputs.size())\n",
    "            output = net(train_inputs.to(device))\n",
    "            loss = LAD_loss(output.cpu(), train_labels.cpu())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        for val_inputs, val_labels in dataloaders['val']:\n",
    "            output = net(val_inputs.to(device))\n",
    "            loss = LAD_loss(output.cpu(), val_labels.cpu())\n",
    "            val_loss += loss\n",
    "            \n",
    "        val_loss = val_loss / len(dataloaders['val'])\n",
    "        \n",
    "        if val_loss < min_val_loss:\n",
    "            torch.save(net, 'Nets')\n",
    "            epochs_no_improve = 0\n",
    "            min_val_loss = val_loss\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == epochs_no_improve_limit:\n",
    "                print('Early stopping initiated')\n",
    "                model = torch.load(checkpoint_path)\n",
    "                print('Best model so far has been loaded')\n",
    "    print('Finished training')\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_inputs))\n",
    "print(np.shape(train_inputs[2][0]))\n",
    "sns.heatmap(train_inputs[1007][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_labels[2160])\n",
    "print(type(train_labels))\n",
    "print(np.shape(train_labels[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(output))\n",
    "print(np.shape(output))\n",
    "sns.heatmap(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt-labi] *",
   "language": "python",
   "name": "conda-env-pt-labi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
