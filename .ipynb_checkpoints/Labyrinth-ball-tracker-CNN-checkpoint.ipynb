{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.1.0\n",
      "Torchvision Version:  0.3.0\n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries needed\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2170, 2, 100, 100)\n",
      "(1, 2, 100, 100)\n",
      "(1, 2, 100, 100)\n",
      "(2170, 100, 100)\n",
      "(1, 100, 100)\n",
      "(1, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# Define the transformations/augmentations for the data\n",
    "array_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "# Tell the dataloader where to search\n",
    "traindir = 'Data/traindir'\n",
    "train_channels = [f'{traindir}/r_data', f'{traindir}/g_data']\n",
    "\n",
    "valdir = 'Data/valdir'\n",
    "val_channels = [f'{valdir}/r_data', f'{valdir}/g_data']\n",
    "\n",
    "testdir = 'Data/testdir'\n",
    "test_channels = [f'{testdir}/r_data', f'{testdir}/g_data']\n",
    "\n",
    "train_inputs = []\n",
    "train_labels = []\n",
    "\n",
    "val_inputs = []\n",
    "val_labels = []\n",
    "\n",
    "test_inputs = []\n",
    "test_labels = []\n",
    "\n",
    "def load_npy_arrays(phase):\n",
    "    \n",
    "    if phase == \"train\":\n",
    "        phase_channels = train_channels\n",
    "        phase_inputs = train_inputs\n",
    "        phasedir = traindir\n",
    "        phase_labels = train_labels\n",
    "    \n",
    "    elif phase == \"val\":\n",
    "        phase_channels = val_channels\n",
    "        phase_inputs = val_inputs\n",
    "        phasedir = valdir\n",
    "        phase_labels = val_labels\n",
    "    \n",
    "    elif phase == \"test\":\n",
    "        phase_channels = test_channels\n",
    "        phase_inputs = test_inputs\n",
    "        phasedir = testdir\n",
    "        phase_labels = test_labels\n",
    "    \n",
    "    else:\n",
    "        print('Valueerror: please pass one of the three accepted values(train, val, test)')\n",
    "\n",
    "    for channel in phase_channels:\n",
    "        path_to_channel = os.fsdecode(channel)\n",
    "        for file in os.listdir(channel):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith('.npy'):\n",
    "                loaded_array = np.load(f'{path_to_channel}/{filename}')\n",
    "                phase_inputs.append(loaded_array)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    labelfolder = f'{phasedir}/labels'\n",
    "    for file in os.listdir(labelfolder):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith('.npy'):\n",
    "            loaded_array = np.load(f'{labelfolder}/{filename}')\n",
    "            phase_labels.append(loaded_array)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "load_npy_arrays(\"train\")\n",
    "load_npy_arrays(\"val\")\n",
    "load_npy_arrays(\"test\")\n",
    "\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, inputs, labels, transform=None):\n",
    "        self.inputs = torch.FloatTensor(inputs)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.inputs[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(self.inputs[index].numpy().astype(np.uint8).transpose(1,2,0))\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "# Split up the red and green channel again so that the axes match in size\n",
    "train_inputs = np.asarray(train_inputs)\n",
    "train_inputs = np.split(train_inputs, 2, axis=0)\n",
    "train_inputs = np.asarray(train_inputs).transpose(1,0,2,3)\n",
    "print(np.shape(train_inputs))\n",
    "\n",
    "val_inputs = np.asarray(val_inputs)\n",
    "val_inputs = np.split(val_inputs, 2, axis=0)\n",
    "val_inputs = np.asarray(val_inputs).transpose(1,0,2,3)\n",
    "print(np.shape(val_inputs))\n",
    "\n",
    "test_inputs = np.asarray(test_inputs)\n",
    "test_inputs = np.split(test_inputs, 2, axis=0)\n",
    "test_inputs = np.asarray(test_inputs).transpose(1,0,2,3)\n",
    "print(np.shape(test_inputs))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(val_labels))\n",
    "print(np.shape(test_labels))\n",
    "\n",
    "# Get the data, transform it\n",
    "data = {\n",
    "   'train':\n",
    "   CreateDataset(train_inputs, train_labels, transform = array_transforms['train']),\n",
    "   'val':\n",
    "   CreateDataset(val_inputs, val_labels, transform = array_transforms['val']),\n",
    "    'test':\n",
    "   CreateDataset(test_inputs, test_labels, transform = array_transforms['test']),\n",
    "}\n",
    "# transform = array_transforms['test']\n",
    "# Load Data in batches, shuffled\n",
    "dataloaders = {\n",
    "   'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "   'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): Identity()\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): Identity()\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): Identity()\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): Identity()\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load in pretrained VGG16 net, extract the FCN part, delete pooling layers,\n",
    "# modify first layer to recieve 2 channels, the last one to output depth 1\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16_mod = vgg16.features\n",
    "vgg16_mod[0] = nn.Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "vgg16_mod[4] = nn.Identity()\n",
    "vgg16_mod[9] = nn.Identity()\n",
    "vgg16_mod[16] = nn.Identity()\n",
    "vgg16_mod[23] = nn.Identity()\n",
    "vgg16_mod[28] = nn.Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "vgg16_mod[30] = nn.Identity()\n",
    "print(vgg16_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on your GeForce 920M (GPU)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and move the model over to GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda: 0\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    print(f\"Running on your {gpu_name} (GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on your CPU\")\n",
    "\n",
    "net = vgg16_mod.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "Training Loss: 286.0875\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n",
      "Training Loss: 3.1422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a33d4f8cd9b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training complete in {:.0f}m {:.0f}s'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_elapsed\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-a33d4f8cd9b7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training Loss: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the training loop with loss-function and optimizer\n",
    "\n",
    "loss_fn = nn.L1Loss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1\n",
    "epochs_no_improve_limit = 7\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epochs_no_improve = 0\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "def train():\n",
    "    since = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "        print('-' * 10)\n",
    "        val_loss = 0\n",
    "        \n",
    "        for train_inputs, train_labels in dataloaders['train']:\n",
    "            optimizer.zero_grad()\n",
    "            output = net(train_inputs.to(device)).reshape(1, 100, 100)\n",
    "            loss = loss_fn(output.cpu(), train_labels.cpu())\n",
    "            train_losses.append(loss)\n",
    "            print('Training Loss: {:.4f}'.format(loss))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        for val_inputs, val_labels in dataloaders['val']:\n",
    "            output = net(val_inputs.to(device))\n",
    "            loss = loss_fn(output.cpu(), val_labels.cpu())\n",
    "            val_loss += loss\n",
    "            \n",
    "        val_loss = val_loss / len(dataloaders['val'])\n",
    "        val_losses.append(val_loss)\n",
    "        print('Validation Loss: {:.4f}'.format(val_loss))\n",
    "        \n",
    "        if val_loss < min_val_loss:\n",
    "            torch.save(net, 'Nets')\n",
    "            epochs_no_improve = 0\n",
    "            min_val_loss = val_loss\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == epochs_no_improve_limit:\n",
    "                print('Early stopping initiated')\n",
    "                model = torch.load(checkpoint_path)\n",
    "                print('Best model so far has been loaded')\n",
    "    print('Least validation Loss: {:4f}'.format(min_val_loss))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Finished training')\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing loop and output some heatmaps\n",
    "# to estimate the performance of the CNN(FCN)\n",
    "\n",
    "test_samples = 5\n",
    "\n",
    "def test():\n",
    "    for test_sample in range(test_samples):\n",
    "        for test_inputs, test_labels in dataloaders['test']:\n",
    "            output = net(test_inputs.to(device))\n",
    "            loss = loss_fn(output.cpu(), test_labels.cpu())\n",
    "            sns.heatmap(output)\n",
    "            sns.heatmap(test_label)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_inputs[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt-labi] *",
   "language": "python",
   "name": "conda-env-pt-labi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
