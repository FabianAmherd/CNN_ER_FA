{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n",
      "Torchvision Version:  0.5.0\n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries needed\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Data/testdir/g_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-997ab0060025>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdatadir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatadirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mload_npy_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatadir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-997ab0060025>\u001b[0m in \u001b[0;36mload_npy_inputs\u001b[1;34m(path_to_dir, phase)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphase_channels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mpath_to_channel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_channel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Data/testdir/g_data'"
     ]
    }
   ],
   "source": [
    "# Define the transformations for the data\n",
    "array_transforms = {\n",
    "    # Training data is augmented\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "#        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "#        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "#        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation data is not augmented\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "#        transforms.Resize(size=256),\n",
    "#        transforms.CenterCrop(size=224),\n",
    "        transforms.RandomRotation(degrees=180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "#        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "# Tell the dataloader where to search\n",
    "traindir = 'Data/traindir'\n",
    "valdir = 'Data/valdir'\n",
    "testdir = 'Data/testdir'\n",
    "datadirs = {traindir, valdir, testdir}\n",
    "\n",
    "# train_r = os.fsencode('Data/jAER_simplest_by_hand_better/traindir/r_data')\n",
    "# train_g = os.fsencode('Data/jAER_simplest_by_hand_better/traindir/g_data')\n",
    "# train_channels = {train_r, train_g}\n",
    "\n",
    "train_inputs = []\n",
    "train_labels = []\n",
    "\n",
    "val_inputs = []\n",
    "val_labels = []\n",
    "\n",
    "test_inputs = []\n",
    "test_labels = []\n",
    "\n",
    "def load_npy_inputs(path_to_dir, phase):\n",
    "    \n",
    "    phase_r = os.fsencode(f'{path_to_dir}/r_data')\n",
    "    phase_g = os.fsencode(f'{path_to_dir}/g_data')\n",
    "    phase_channels = {phase_r, phase_g}\n",
    "    \n",
    "    for channel in phase_channels:\n",
    "        path_to_channel = os.fsdecode(channel)\n",
    "        os.chdir(path_to_channel)\n",
    "        for file in os.listdir(channel):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith('.npy'):\n",
    "                loaded_array = np.load(f'{path_to_channel}/{filename}')\n",
    "                phase_inputs.append(loaded_array)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "for datadir in datadirs:\n",
    "    load_npy_inputs(datadir, datadir[:-3])\n",
    "    \n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, inputs, labels, transform=None):\n",
    "        self.inputs = inputs\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.inputs[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(self.inputs[index].astype(np.uint8).transpose(1,2,0))\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "\n",
    "# Get the data as Tensors\n",
    "data = {\n",
    "   'train':\n",
    "   CreateDataset(train_inputs, train_labels, transform = array_transforms['train']),\n",
    "   'val':\n",
    "   CreateDataset(val_inputs, val_labels, transform = array_transforms['val']),\n",
    "}\n",
    "\n",
    "# Load Data in batches, shuffled\n",
    "dataloaders = {\n",
    "   'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "   'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in pretrained VGG16 net and extract the fully convolutional part\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16_mod = vgg16.features\n",
    "print(vgg16_mod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt-labi] *",
   "language": "python",
   "name": "conda-env-pt-labi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
